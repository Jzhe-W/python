# CWGAN-GP é£ç”µæ•°æ®ç”Ÿæˆä¼˜åŒ–å»ºè®®

## ğŸ“Š ä¸»è¦é—®é¢˜åˆ†æ

### 1. **è¶…å‚æ•°ä¼˜åŒ–ä¸è¶³** âš ï¸
```python
# å½“å‰é—®é¢˜
n_trials=2  # ä»…2æ¬¡è¯•éªŒ
ultra_fast_epochs=5  # ä»…5è½®è®­ç»ƒ
```
**å½±å“**ï¼šæ— æ³•æ‰¾åˆ°çœŸæ­£çš„æœ€ä¼˜å‚æ•°ç»„åˆ

### 2. **æŸå¤±æƒé‡å¤±è¡¡** âš ï¸
```python
# é˜¶æ®µ1+2æƒé‡è°ƒæ•´å¯èƒ½çŸ«æ‰è¿‡æ­£
5.0 * similarity_loss   # æé«˜10å€
5.0 * mag_loss          # æé«˜2.5å€
0.5 * div_loss          # é™ä½4å€
```
**å½±å“**ï¼šæ¨¡å‹è¿‡åº¦è¿½æ±‚ç›¸ä¼¼æ€§ï¼Œç‰ºç‰²äº†å¤šæ ·æ€§å’Œæ³›åŒ–èƒ½åŠ›

### 3. **å­£èŠ‚ç‰¹æ®Šå¤„ç†è¿‡åº¦** âš ï¸
- Summerä½¿ç”¨2.5å€å™ªå£°
- Winterä½¿ç”¨2.0å€å™ªå£°
- å¤šä¸ªç¡¬ç¼–ç çš„å­£èŠ‚çº¦æŸ
**å½±å“**ï¼šç ´åäº†æ¨¡å‹çš„ç»Ÿä¸€æ€§ï¼Œéš¾ä»¥åè°ƒ

### 4. **åŒé‡å½’ä¸€åŒ–é—®é¢˜** âš ï¸
```python
# Z-score â†’ MinMax â†’ [0,1]
# åå½’ä¸€åŒ–æ—¶å®¹æ˜“å‡ºé”™
```
**å½±å“**ï¼šä¿¡æ¯æŸå¤±ï¼Œåå½’ä¸€åŒ–ä¸å‡†ç¡®

### 5. **ACFæŸå¤±è¢«å®Œå…¨ç¦ç”¨** âš ï¸
```python
acf_reg_loss = torch.tensor(0.0, device=gen_curves.device)
```
**å½±å“**ï¼šä¸¢å¤±äº†æ—¶åºç›¸å…³æ€§ç‰¹å¾

---

## ğŸš€ ä¼˜åŒ–æ–¹æ¡ˆ

### æ–¹æ¡ˆAï¼šæ¸è¿›å¼ä¼˜åŒ–ï¼ˆæ¨èï¼‰

#### Step 1: å¢åŠ è¶…å‚æ•°ä¼˜åŒ–å¼ºåº¦
```python
# ä¿®æ”¹è¶…å‚æ•°ä¼˜åŒ–é…ç½®
optimizer = SimpleHyperparameterOptimizer(
    train_dataset, val_dataset, 
    n_trials=10,              # 2 â†’ 10
    ultra_fast_mode=False     # å…³é—­æé€Ÿæ¨¡å¼
)
optimizer.ultra_fast_epochs = 30  # 5 â†’ 30
```

#### Step 2: é‡æ–°å¹³è¡¡æŸå¤±æƒé‡
```python
# å»ºè®®çš„å¹³è¡¡æƒé‡ï¼ˆåŸºäºWGAN-GPæœ€ä½³å®è·µï¼‰
total_loss_G = (
    loss_G + aux_loss_G +
    
    # ç›¸ä¼¼æ€§ï¼ˆé€‚åº¦é™ä½ï¼‰
    2.0 * similarity_loss +      # 5.0 â†’ 2.0
    2.0 * mag_loss +             # 5.0 â†’ 2.0
    
    # å¤šæ ·æ€§ï¼ˆé€‚åº¦æé«˜ï¼‰
    1.5 * div_loss +             # 0.5 â†’ 1.5
    2.0 * intra_div_loss +       # 0.8 â†’ 2.0
    
    # é˜¶æ®µ2æŸå¤±ï¼ˆé€‚åº¦é™ä½ï¼‰
    1.5 * pointwise_loss +       # 3.0 â†’ 1.5
    1.0 * segment_loss +         # 2.0 â†’ 1.0
    1.0 * peak_valley_loss +     # 2.0 â†’ 1.0
    1.0 * dist_loss +            # 1.5 â†’ 1.0
    
    # æ—¶åºï¼ˆé€‚åº¦æ¢å¤ï¼‰
    0.3 * temporal_loss +        # 0.02 â†’ 0.3
    0.2 * freq_loss +            # 0.02 â†’ 0.2
    
    # é£ç”µçº¦æŸï¼ˆä¿æŒï¼‰
    2.0 * wind_physical_loss +
    5.0 * wind_physical_loss_v2 +
    10.0 * wind_constraint
)
```

#### Step 3: ç»Ÿä¸€å­£èŠ‚å™ªå£°ç­–ç•¥
```python
# ç§»é™¤è¿‡åº¦çš„å­£èŠ‚ç‰¹æ®Šå¤„ç†
# ç»Ÿä¸€ä½¿ç”¨åŠ¨æ€å™ªå£°è°ƒæ•´
progress = epoch / epochs
base_noise = noise_sigma * (1.0 + 0.5 * np.sin(2 * np.pi * progress))

# æ‰€æœ‰å­£èŠ‚ä½¿ç”¨ç»Ÿä¸€ç­–ç•¥
z = torch.randn(batch_size, z_dim, device=device) * base_noise + noise_mu
```

#### Step 4: ç®€åŒ–å½’ä¸€åŒ–æ–¹æ¡ˆ
```python
# åªä½¿ç”¨MinMaxå½’ä¸€åŒ–ï¼ˆç§»é™¤Z-scoreï¼‰
scaler = MinMaxScaler(feature_range=(0, 1))
data_norm = scaler.fit_transform(data.values.T).T

# åå½’ä¸€åŒ–ä¹Ÿæ›´ç®€å•
fake_denorm = scaler.inverse_transform(fake_all.T).T
```

#### Step 5: æ¢å¤è½»é‡çº§ACFçº¦æŸ
```python
# ä½¿ç”¨è½»é‡çº§ACFæŸå¤±ï¼ˆåªçº¦æŸå‰5ä¸ªlagï¼‰
def lightweight_acf_loss(fake_curves, max_lag=5):
    acf_loss = 0
    for lag in range(1, max_lag + 1):
        curve_t = fake_curves[:, :-lag]
        curve_t_lag = fake_curves[:, lag:]
        corr = torch.mean(curve_t * curve_t_lag)
        expected = torch.exp(torch.tensor(-0.1 * lag, device=fake_curves.device))
        acf_loss += torch.abs(corr - expected)
    return acf_loss / max_lag

# æ·»åŠ åˆ°æ€»æŸå¤±
total_loss_G += 0.5 * lightweight_acf_loss(gen_curves)
```

---

### æ–¹æ¡ˆBï¼šæ¿€è¿›å¼ä¼˜åŒ–ï¼ˆå¿«é€Ÿå®éªŒï¼‰

#### å®Œå…¨é‡æ„æŸå¤±å‡½æ•°
```python
# æç®€åŒ–çš„æŸå¤±å‡½æ•°ï¼ˆåŸºäºVanilla WGAN-GPï¼‰
total_loss_G = (
    loss_G +                          # WGANæ ¸å¿ƒæŸå¤±
    aux_loss_G +                      # è¾…åŠ©åˆ†ç±»æŸå¤±
    1.0 * F.mse_loss(gen_curves, real_curves) +  # ç®€å•MSE
    0.5 * seasonal_diversity_loss(gen_curves, season_vec)  # æœ€å°å¤šæ ·æ€§
)
```

#### ç§»é™¤æ‰€æœ‰å­£èŠ‚ç‰¹æ®Šå¤„ç†
```python
# ç»Ÿä¸€å™ªå£°ç­–ç•¥
z = torch.randn(batch_size, z_dim, device=device) * noise_sigma

# ç§»é™¤æ‰€æœ‰if summer_mask / winter_maskåˆ†æ”¯
```

---

### æ–¹æ¡ˆCï¼šæ•°æ®é©±åŠ¨ä¼˜åŒ–

#### 1. åˆ†æçœŸå®æ•°æ®ç‰¹å¾
```python
# æ·»åŠ çœŸå®æ•°æ®ç‰¹å¾åˆ†æ
def analyze_real_data(data, season_labels):
    """åˆ†æçœŸå®æ•°æ®çš„ç»Ÿè®¡ç‰¹å¾"""
    for season in range(4):
        season_data = data[season_labels[:, season] == 1]
        print(f"{season_names[season]}:")
        print(f"  å‡å€¼: {season_data.mean():.4f}")
        print(f"  æ ‡å‡†å·®: {season_data.std():.4f}")
        print(f"  å³°å€¼: {season_data.max():.4f}")
        print(f"  è°·å€¼: {season_data.min():.4f}")
        print(f"  å˜åŒ–ç‡: {np.diff(season_data).std():.4f}")

# åœ¨è®­ç»ƒå‰è°ƒç”¨
analyze_real_data(train_data.values.T, train_labels)
```

#### 2. åŸºäºåˆ†æè°ƒæ•´çº¦æŸ
æ ¹æ®çœŸå®æ•°æ®çš„å®é™…ç»Ÿè®¡ç‰¹å¾ï¼ŒåŠ¨æ€è®¾ç½®çº¦æŸç›®æ ‡

---

## ğŸ¯ å¿«é€Ÿè¯Šæ–­æ¸…å•

è¿è¡Œä»¥ä¸‹ä»£ç è¯Šæ–­å½“å‰æ¨¡å‹çŠ¶æ€ï¼š

```python
# æ·»åŠ åˆ°è®­ç»ƒå¾ªç¯ä¸­
if epoch % 50 == 0:
    print("\n=== æ¨¡å‹è¯Šæ–­ ===")
    print(f"1. Wè·ç¦»: {avg_wasserstein:.4f} (ç›®æ ‡: <0.1)")
    print(f"2. å­£èŠ‚å·®å¼‚: {avg_season_diff:.4f} (ç›®æ ‡: >0.15)")
    print(f"3. ç”Ÿæˆå™¨æŸå¤±: {avg_loss_G:.4f}")
    print(f"4. åˆ¤åˆ«å™¨æŸå¤±: {avg_loss_D:.4f}")
    
    # ç”Ÿæˆæ ·æœ¬æ£€æŸ¥
    with torch.no_grad():
        z_test = torch.randn(16, z_dim, device=device) * noise_sigma
        season_test = torch.eye(4, device=device).repeat(4, 1)
        fake_test = G(z_test, season_test, 0).detach().cpu().numpy()
        
        print(f"5. ç”Ÿæˆæ•°æ®èŒƒå›´: [{fake_test.min():.4f}, {fake_test.max():.4f}]")
        print(f"6. ç”Ÿæˆæ•°æ®å‡å€¼: {fake_test.mean():.4f}")
        print(f"7. ç”Ÿæˆæ•°æ®æ ‡å‡†å·®: {fake_test.std():.4f}")
```

---

## ğŸ“‹ æ¨èæ‰§è¡Œé¡ºåº

### é˜¶æ®µ1ï¼šå¿«é€ŸéªŒè¯ï¼ˆ1-2å°æ—¶ï¼‰
1. âœ… ä½¿ç”¨æ–¹æ¡ˆBçš„æç®€æŸå¤±å‡½æ•°
2. âœ… è®­ç»ƒ200è½®ï¼Œè§‚å¯ŸWè·ç¦»å’ŒMAPE
3. âœ… å¦‚æœMAPEæ˜¾è‘—é™ä½ï¼ˆ<200%ï¼‰ï¼Œè¯´æ˜è¿‡åº¦å¤æ‚åŒ–æ˜¯ä¸»è¦é—®é¢˜

### é˜¶æ®µ2ï¼šç²¾ç»†è°ƒä¼˜ï¼ˆ3-5å°æ—¶ï¼‰
1. âœ… å®æ–½æ–¹æ¡ˆAçš„Step 1-3
2. âœ… è®­ç»ƒ500è½®ï¼Œè®°å½•æœ€ä½³æ¨¡å‹
3. âœ… å¯¹æ¯”ä¼˜åŒ–å‰åçš„æŒ‡æ ‡

### é˜¶æ®µ3ï¼šæ·±åº¦ä¼˜åŒ–ï¼ˆå¯é€‰ï¼‰
1. âœ… å®æ–½æ–¹æ¡ˆCçš„æ•°æ®åˆ†æ
2. âœ… åŸºäºåˆ†æç»“æœå¾®è°ƒçº¦æŸ
3. âœ… è®­ç»ƒå®Œæ•´çš„2000è½®

---

## ğŸ”§ å…³é”®å‚æ•°å»ºè®®å€¼

```python
# è¶…å‚æ•°ä¼˜åŒ–
n_trials = 10
ultra_fast_epochs = 30

# è®­ç»ƒå‚æ•°
epochs = 1000  # 2000 â†’ 1000ï¼ˆå…ˆçœ‹æ•ˆæœï¼‰
batch_size = 32  # 64 â†’ 32ï¼ˆæé«˜ç¨³å®šæ€§ï¼‰
n_critic = 3  # 5 â†’ 3ï¼ˆåŠ å¿«Gæ›´æ–°ï¼‰

# å­¦ä¹ ç‡
lr_G = 2e-4  # ä¿æŒ
lr_D = 1e-4  # ä¿æŒ

# å™ªå£°
noise_sigma = 0.2  # ç»Ÿä¸€ä½¿ç”¨ï¼Œä¸åˆ†å­£èŠ‚

# æ—©åœ
early_stopping_patience = 100  # 50 â†’ 100
```

---

## ğŸ¯ é¢„æœŸæ”¹å–„

å®æ–½ä¼˜åŒ–åçš„é¢„æœŸæŒ‡æ ‡ï¼š
- **Summer MAPE**: 400-500% â†’ **150-250%**
- **æ•´ä½“MAPE**: 200-300% â†’ **100-150%**
- **Wè·ç¦»**: >0.5 â†’ **<0.1**
- **è®­ç»ƒç¨³å®šæ€§**: æ˜¾è‘—æå‡
- **æ”¶æ•›é€Ÿåº¦**: æé«˜2-3å€

